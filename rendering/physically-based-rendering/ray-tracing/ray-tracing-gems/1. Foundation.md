

# 1. Ray AABB intersection


For ray tracing acceleration structures, we need to know if a ray hits a bounding object.

For this, Here are two things that we need
 - AABB object
 - slab test developed by Kay and Kajiya

## Introduction to slab test
-  a ray represented as $p(t) = o + t \cdot v$  , where $v$ is a direction of the ray and $o$ is the origin of ray.
- A ray intersects with three 'slabs' and then seeing if it is ever within all three slabs at once.
	-> Then it truly intersects with AABB object.

**Then what is slab ?**
A slab is the region of space **enclosed by two parallel planes.**


For example, Let's say that an AABB has x-slab region of space between the two planes at $x=x_0,\space x=x_1$.
If the ray is not parallel to the slab region, it should intersect with two specific points on each planes. 
Assuming that the ray intersects with the planes, the ray will have each intersection points with the coefficients of t-value $t_{x0}$ and $t_{x1}$.


## Slab test algorithm
This is widely used implementation for slab test

```cpp
bool slabsBoxTest(
	vec3 p0, vec3 p1, 
	vec3 rayOrigin, vec3 inverseRayDir,
	float tmin, float tmax)
{
	// (point - ray origin) is equivalent to direction of ray(but not normalized).
	// By multiplying inverse of ray direction(normalized), we can extract t-value in the result of dot product. 
	vec3 tLower = (p0 - rayOrigin)*inverseRayDir;
	vec3 tUpper = (p1 - rayOrigin)*inverseRayDir;

// determine min and max among slab intersections.
	vec4 tMins  = vec4(min(tLower, tUpper), tmin);
	vec4 tMaxes = vec4(max(tLower, tUpper), tmax);

	float tBoxMin = max_component(tMins);
	float tBoxMax = min_component(tMaxes);

// if maximum among tMins is larger than minimum of tMaxes, it means that the intersection is out of AABB region.

	return tBoxMin <= tBoxMax;
}
```



---
# 2. Essential ray generation shaders

In realtime ray tracing programs, the most fundamental step is to setup 'raygen' shaders that produces the rays themselves.

## Types of ray generation projection

- pinhole (perspective) : standard / rectilinear / planar form
- thin lens (DOF) : gaussian lens modle 
- generalized panini : better than pinhole
- fisheye : wide field of view for pinhole
- lenslet : light field slab parameterization
- octahedral : good for reflection probes
- cube map : texel to ray, ray to texel transformation
- orthographic (scientific and engineering visualization)
- fibonacci uniform sphere (for ambient occlusion and radiosity)

## Camera Rays
- origin space of rays (not exactly equivalent to real-world camera)
- we always assume that the camera's axes are orthonormal.

- A ray struct
```cpp
struct Ray {
	vec3  pos;
	float tmin;
	float tmax;
	vec3  dir;
}
```

- Transformation a camera ray from local space to world space
```cpp
worldRay.dir = matmul(cameraRotationMat, cameraRay.dir);
worldRay.pos = cameraTranslationMat + cameraRay.pos;
```

- In Vulkan, instance transformation matrix is represented as 4 by 3 matrix, which is 3 by 3 matrix for linear transformation and last 4th column for affine transformation such as translation.
```cpp
wordRay.dir = matmul(cameraRay.dir, mat3x3(worldToCamera));
wordRay.pos = worldToCamera[3] + cameraRay.pos;
```

## Near and Far planes


Ray tracing doesn't require a near or far clipping plane in terms of mathematics.
But there are several reasons that we need them.
- the performance of ray tracing decrease as the length of the ray increase(maximum t-value) in general
- When an object comes very close to the camera, the object can become too large and confuse viewer.

By modifying the value of tmin and tmax, we can control the near and far clipping effect.

## Supersampling
In rasterization, Aliasing artifacts can be reducet by averaging the contributions of  texel, which is known as MSAA(multisampling anti-aliasing)

To apply a **subpixel offset** to each ray, we can change the fractional pixel coordinate before computing the ray itself

**How to change the fractional coordinate ?**
we can utilize 2, 3 Halton sequence to create a random number and precompute the sampled pixel coordinates(this generator has $O(N log N)$ complexity), then pass it to the ray generation shader.

## Camera Parameters


## camera parameters
```cpp
// edge to edge field of view, radians unit
float cameraFOVAngle;

// 0 = cameraFOV is horizontal direction
// 1 = vertical
// 2 = diagonal(only for fish-eye)
int cameraFOVDirection;

// width and height integers stored as floats to avoid conversion
vec2 imageSize; // also called as resolution

// center of projection from cylinder to plane
float paniniDistance;
// 0 ~ 1 value to force straightening of horizontal lines
float paniniVerticalCompression;
// scalar field of view in m, used for orthographic projection
float cameraFovDistance;
// lens focal length in meters
float lensFocalLength;
// ratio of focal length of aperture diameter
float fStop;

// Distance from the image plane to the lens
float imagePlaneDistnace;
```


## Pinhole perspective

- The black point in below picture is a 'pinhole aperture' (with zero radius of aperture)

![](../../../../images/Pasted%20image%2020240512154314.png)

## Thin Lens

A single, thin lens can produce mathematically ideal focus for a single frequency of light and a small image.

The Standard model of an ideal lens is called the *Gaussian thin lens model*










---






---
 

# 3. Hacking the shadow terminator

## Introduction
- In 3D rendering , geometry is often represented as a polygon mesh
- Nowadays triangle meshes is very popular choice.
	For example, individual quad can be represented as two quads.
- Traditionally, shading is performed using a normal resulting from barycentric interpolation of vertex normals across triangle.

Incosistent normals with the geometric surface normal can lead to various issues

1. On the left side, we want to render dashed surface, but an accurate representation is too expensive to intersect with a ray. Because the side of triangle that faces viewer is facing away from light source, it will be completely black.
	A well-known solution is user-driven epsilon values to push out the shading point from the triangle surface.
![](../../../../images/Pasted%20image%2020240514120650.png)


## Moving the intersection point in hindsight

- How a simple quadratic Bezier patch is constructed from vertices and vertex normals?
	de Casteljau's algorithm
		1. construct additional control points $AB, BC, CA$ 
		2. use barycentric coordinates $u,v,w$ to copmute additional vertices $A', B', C'$ from the three triangles $(A, AB, CA), (AB, B, BC), (CA, BC, C)$ respectively.
		3. These three additional vertices form a new triangle, which we interpolate once more with the barycentric coordinates $u,v,w$ to finally arrive at $P'$
![](../../../../images/Pasted%20image%2020240514122759.png)


- How to place the extra control points such as AB

# 4. Sampling Textures with missing derivatives

- First-order differentials of texture coordinates : a key part of rendering high quality imagery **without aliasing**
- a common techinque in rasterization is to compute differences among **adjacent pixels in a 2 x 2 quad of pixels.**
	But these techniques is not always possible with modern rendering algorithms (such as deffered shading , ray tracing)

- Methods based on 'ray differentials' and 'ray cones' have applied to this problem in ray tracing

## Introduction

- A modern GPU pixel shaders provide explicit derivation functions 
	- In HLSL, `ddx()` , `ddy()` 
	- In GLSL, `dFdx()` , `dFdy()`
	- Above functions has an ability to estimate derivatives of any expression by computing first-order.
- texture lookup function is used in shader
	-> GPU compute the derivatives based on the provided texture coordinates.
	-> By doing so, Determine ==**which mip level to use**== as well as  ==What area to filter over in that mip level==

But in ray tracing or deferred shading , those functions may be either not available or not applicable.

In ray tracing, methods like ray differentials have been applied to carry dervitaive information along with rays.
	By giving an accurate texture coordinate derivative estimates, it leads to well anti-aliased image, But with a relatively high cost.
	Especially In GPU, It is important to keep a smaller ray payload size for high.

Akenine-Moller have developed more **lightweight** ray derivative representations.
This approach can compute texture derivatives on geometry that is directly visible from the camera ==without using any auxiliary storage.==


## Texture coordinate derivatives at visible points


---


# References

- [Ray tracing gems 2](https://www.apress.com/gp/ray-tracing-gems-ii/19545578)